# C√≥digo de Exemplo: Implementa√ß√£o FASE 2.1

**Objetivo:** Mostrar exatamente o que adicionar ao `client_dashboard.py`

---

## 1. ESTENDER `calculate_metrics()` 

### Arquivo: `/src/multi_tenant/dashboards/client_dashboard.py`

**Localiza√ß√£o Atual (linha ~182):**
```python
def calculate_metrics(df):
    """Calcula m√©tricas principais do dashboard"""
    if df.empty:
        return {
            'total_contacts': 0,
            'ai_conversations': 0,
            'leads': 0,
            'visits_scheduled': 0,
            'crm_converted': 0,
        }

    metrics = {
        'total_contacts': len(df),
        'ai_conversations': len(df[df['bot_messages'] > 0]),
        'leads': len(df[df['is_lead'] == True]),
        'visits_scheduled': len(df[df['visit_scheduled'] == True]),
        'crm_converted': len(df[df['crm_converted'] == True]),
    }

    return metrics
```

**Substituir por:**
```python
def calculate_metrics(df):
    """
    Calcula m√©tricas principais do dashboard
    
    Agora inclui:
    - M√©tricas de qualidade (IA%, Resolu√ß√£o, etc)
    - Performance (tempo resposta)
    """
    if df.empty:
        return {
            'total_contacts': 0,
            'ai_conversations': 0,
            'human_conversations': 0,
            'leads': 0,
            'visits_scheduled': 0,
            'crm_converted': 0,
            'resolution_rate': 0.0,
            'avg_response_time': 0.0,
        }

    total = len(df)
    
    # M√©tricas Existentes
    metrics = {
        'total_contacts': total,
        'ai_conversations': len(df[df['has_human_intervention'] == False]),
        'human_conversations': len(df[df['has_human_intervention'] == True]),
        'leads': len(df[df['is_lead'] == True]),
        'visits_scheduled': len(df[df['visit_scheduled'] == True]),
        'crm_converted': len(df[df['crm_converted'] == True]),
    }
    
    # NOVAS - M√©tricas de Qualidade [FASE 2.1]
    resolved_count = len(df[df['is_resolved'] == True]) if 'is_resolved' in df.columns else 0
    metrics['resolution_rate'] = (resolved_count / total * 100) if total > 0 else 0.0
    
    # Tempo resposta m√©dio (em minutos)
    if 'first_response_time_minutes' in df.columns:
        valid_times = df[df['first_response_time_minutes'].notna()]['first_response_time_minutes']
        metrics['avg_response_time'] = valid_times.mean() if len(valid_times) > 0 else 0.0
    else:
        metrics['avg_response_time'] = 0.0

    return metrics
```

---

## 2. NOVA FUN√á√ÉO: Distribui√ß√£o por Per√≠odo

### Adicionar Ap√≥s `prepare_score_distribution()`:

```python
def prepare_period_distribution(df):
    """
    Prepara dados de distribui√ß√£o de conversas por per√≠odo do dia
    
    Args:
        df: DataFrame com conversas
    
    Returns:
        pd.DataFrame: Distribui√ß√£o por per√≠odo (Manh√£/Tarde/Noite/Madrugada)
    """
    if df.empty or 'conversation_period' not in df.columns:
        return pd.DataFrame(columns=['Per√≠odo', 'Quantidade'])
    
    # Agrupar por per√≠odo
    period_dist = df.groupby('conversation_period').size().reset_index(name='Quantidade')
    period_dist.rename(columns={'conversation_period': 'Per√≠odo'}, inplace=True)
    
    # Ordenar por ordem l√≥gica dos per√≠odos
    period_order = {'Manh√£': 1, 'Tarde': 2, 'Noite': 3, 'Madrugada': 4}
    period_dist['_order'] = period_dist['Per√≠odo'].map(period_order)
    period_dist = period_dist.sort_values('_order').drop('_order', axis=1)
    
    return period_dist
```

---

## 3. NOVA FUN√á√ÉO: Render KPIs de Qualidade

### Adicionar Ap√≥s `render_kpis()`:

```python
def render_quality_metrics(metrics, df):
    """
    Renderiza m√©trica de qualidade (IA%, Resolu√ß√£o%, Tempo Resposta)
    
    Args:
        metrics: Dict com m√©tricas calculadas
        df: DataFrame com conversas
    """
    st.divider()
    st.subheader("‚öôÔ∏è M√©tricas de Qualidade")
    
    col1, col2, col3, col4 = st.columns(4)
    
    total = len(df) if not df.empty else 1
    
    with col1:
        pct_ai = (metrics['ai_conversations'] / total * 100) if total > 0 else 0
        st.metric(
            "Conversas IA %",
            f"{pct_ai:.1f}%",
            help="Percentual de conversas 100% autom√°ticas (sem interven√ß√£o humana)"
        )
    
    with col2:
        st.metric(
            "Taxa Resolu√ß√£o",
            f"{metrics['resolution_rate']:.1f}%",
            help="Percentual de conversas resolvidas"
        )
    
    with col3:
        st.metric(
            "Tempo Resposta",
            f"{metrics['avg_response_time']:.0f} min",
            help="Tempo m√©dio da primeira resposta"
        )
    
    with col4:
        pct_engagement = (metrics['total_contacts'] / total * 100) if total > 0 else 0
        st.metric(
            "Engagement %",
            f"{pct_engagement:.1f}%",
            help="Percentual de contatos que enviaram mensagens"
        )
```

---

## 4. NOVO GR√ÅFICO: Distribui√ß√£o por Per√≠odo

### Adicionar Ap√≥s `render_score_distribution_chart()`:

```python
def render_period_distribution_chart(period_dist):
    """
    Renderiza gr√°fico de distribui√ß√£o por per√≠odo do dia
    
    Args:
        period_dist: DataFrame com distribui√ß√£o de per√≠odos
    """
    if period_dist.empty:
        st.info("‚ÑπÔ∏è Nenhum dado para exibir")
        return
    
    st.subheader("üïê Distribui√ß√£o por Per√≠odo do Dia")
    
    # Gr√°fico de barras
    st.bar_chart(period_dist.set_index('Per√≠odo')['Quantidade'], use_container_width=True)
    
    # Resumo em colunas
    col1, col2, col3, col4 = st.columns(4)
    cols = [col1, col2, col3, col4]
    
    for idx, (_, row) in enumerate(period_dist.iterrows()):
        if idx < 4:
            with cols[idx]:
                st.metric(row['Per√≠odo'], f"{row['Quantidade']} leads")
```

---

## 5. INTEGRAR NO `show_client_dashboard()`

### Localiza√ß√£o: Linha ~758 (ap√≥s carregar dados)

**Adicionar ap√≥s a se√ß√£o "AN√ÅLISE DE LEADS":**

```python
    # === GR√ÅFICOS === (linhas ~759-777)
    st.subheader("üìä An√°lise de Leads")

    # Linha 1: Leads por dia (largura completa)
    leads_by_day = prepare_leads_by_day(df)
    render_leads_chart(leads_by_day)

    st.divider()

    # Linha 2: Leads por inbox + Distribui√ß√£o de Score (lado a lado)
    col1, col2 = st.columns(2)

    with col1:
        leads_by_inbox = prepare_leads_by_inbox(df)
        render_leads_by_inbox_chart(leads_by_inbox)

    with col2:
        score_dist = prepare_score_distribution(df)
        render_score_distribution_chart(score_dist)

    st.divider()
    
    # [NOVO] Linha 3: Distribui√ß√£o por Per√≠odo + Qualidade
    # Adicionar AQUI:
    
    render_quality_metrics(metrics, df)  # [NOVO]
    
    st.divider()
    
    col1, col2 = st.columns([1.5, 1])
    
    with col1:
        period_dist = prepare_period_distribution(df)
        render_period_distribution_chart(period_dist)  # [NOVO]
    
    with col2:
        st.subheader("üìã Resumo Qualidade")
        st.write(f"""
        - **IA Autom√°ticas:** {metrics['ai_conversations']} conversas
        - **Com Humano:** {metrics['human_conversations']} conversas
        - **Taxa Resolu√ß√£o:** {metrics['resolution_rate']:.1f}%
        - **Tempo Resposta:** {metrics['avg_response_time']:.0f}min
        """)

    st.divider()

    # === TABELA DE LEADS === (linhas ~780-782, permanece igual)
    render_leads_table(df, tenant_name, date_start, date_end)
```

---

## 6. IMPORTS NECESS√ÅRIOS

### Verificar No Topo do Arquivo

Ja est√£o presentes, mas confirmar:

```python
import pandas as pd
import streamlit as st
from datetime import datetime, timedelta
```

---

## 7. ANTES E DEPOIS (Visual)

### ANTES (Current)
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ KPIs (5 cards)      ‚îÇ
‚îÇ Total|Leads|...     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Funil (3 cards)     ‚îÇ
‚îÇ Leads‚ÜíVisitas‚ÜíCRM   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Gr√°ficos (2x2)      ‚îÇ
‚îÇ [Leads/Dia][Inbox]  ‚îÇ
‚îÇ [Score]             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Tabela              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### DEPOIS (Com FASE 2.1)
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ KPIs (5 cards)      ‚îÇ
‚îÇ Total|Leads|...     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ QUALIDADE (4 cards) ‚îÇ [NOVO]
‚îÇ IA%|Resolu√ß√£o|Resp  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Funil (3 cards)     ‚îÇ
‚îÇ Leads‚ÜíVisitas‚ÜíCRM   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Gr√°ficos (2x2)      ‚îÇ
‚îÇ [Leads/Dia][Per√≠odo]‚îÇ [Per√≠odo √© NOVO]
‚îÇ [Inbox][Score]      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Tabela              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 8. TESTE UNIT√ÅRIO

### Criar arquivo: `/tests/test_client_dashboard_metrics.py`

```python
import pandas as pd
import sys
from pathlib import Path

# Simular importa√ß√£o
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

def test_calculate_metrics_with_quality():
    """Testa c√°lculo de m√©tricas com novos campos"""
    
    # Mock data
    df = pd.DataFrame({
        'conversation_id': [1, 2, 3, 4, 5],
        'is_lead': [True, True, False, True, True],
        'visit_scheduled': [True, False, False, True, False],
        'crm_converted': [False, True, False, False, True],
        'has_human_intervention': [False, True, False, False, True],
        'is_resolved': [True, True, False, True, False],
        'first_response_time_minutes': [5, 10, 15, 3, 8],
    })
    
    # Simular fun√ß√£o
    def calculate_metrics(df):
        total = len(df)
        resolved = len(df[df['is_resolved'] == True])
        
        return {
            'total_contacts': total,
            'leads': len(df[df['is_lead'] == True]),
            'ai_conversations': len(df[df['has_human_intervention'] == False]),
            'human_conversations': len(df[df['has_human_intervention'] == True]),
            'resolution_rate': (resolved / total * 100) if total > 0 else 0,
            'avg_response_time': df['first_response_time_minutes'].mean(),
        }
    
    metrics = calculate_metrics(df)
    
    # Asserts
    assert metrics['total_contacts'] == 5
    assert metrics['leads'] == 4
    assert metrics['ai_conversations'] == 3  # FALSE, FALSE, FALSE
    assert metrics['human_conversations'] == 2  # TRUE, TRUE
    assert metrics['resolution_rate'] == 60.0  # 3 de 5
    assert metrics['avg_response_time'] == 8.2  # (5+10+15+3+8)/5
    
    print("‚úÖ Todos os testes passaram!")

if __name__ == "__main__":
    test_calculate_metrics_with_quality()
```

---

## 9. CHECKLIST DE IMPLEMENTA√á√ÉO

### Antes de Come√ßar
- [ ] Confirmar dados do BD est√£o em `conversations_analytics`
- [ ] Verificar campos: `has_human_intervention`, `is_resolved`, `first_response_time_minutes`, `conversation_period`
- [ ] Fazer backup do arquivo original

### Implementa√ß√£o
- [ ] Estender fun√ß√£o `calculate_metrics()`
- [ ] Adicionar fun√ß√£o `prepare_period_distribution()`
- [ ] Adicionar fun√ß√£o `render_quality_metrics()`
- [ ] Adicionar fun√ß√£o `render_period_distribution_chart()`
- [ ] Integrar no fluxo do `show_client_dashboard()`
- [ ] Testar com dados reais do DB

### Valida√ß√£o
- [ ] Verificar se KPIs aparecem corretamente
- [ ] Testar com m√∫ltiplos tenants (RLS)
- [ ] Validar gr√°ficos renderizam corretamente
- [ ] Testar responsividade mobile
- [ ] Verificar performance (cache)

### Deploy
- [ ] Criar PR com descri√ß√£o clara
- [ ] Code review
- [ ] Merge para main/staging
- [ ] Deploy em produ√ß√£o

---

## 10. TROUBLESHOOTING

### Campo `conversation_period` n√£o existe
**Solu√ß√£o:** Verificar se tabela `conversations_analytics` foi atualizada com view completa
```sql
SELECT DISTINCT conversation_period FROM conversations_analytics LIMIT 5;
```

### Valores NaN em `first_response_time_minutes`
**Solu√ß√£o:** J√° tratado no c√≥digo com `.notna()` e `.mean()`
```python
valid_times = df[df['first_response_time_minutes'].notna()]['first_response_time_minutes']
metrics['avg_response_time'] = valid_times.mean() if len(valid_times) > 0 else 0.0
```

### RLS n√£o filtra corretamente
**Solu√ß√£o:** Confirmar que `set_rls_context()` foi chamado antes de `load_conversations()`

---

**Total de Linhas de C√≥digo:** ~80 linhas novas  
**Arquivo Principal:** `client_dashboard.py`  
**Tempo Estimado:** 2-3 horas (implementa√ß√£o + testes)  
**Complexidade:** Baixa (c√≥pia + adapta√ß√£o)

