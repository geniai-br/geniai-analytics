# ADR-002: Pipeline ETL V3 Incremental com Watermark

**Status:** Aceito
**Data:** 2025-11-04
**Decisores:** Equipe GenIAI
**Contexto TÃ©cnico:** Python 3.11, PostgreSQL 15, Pandas 2.0, psycopg2

---

## Contexto e Problema

O sistema precisa sincronizar dados do Chatwoot (banco remoto) para o banco local de analytics:

### Requisitos
1. **Volume:** ~300.000+ conversas, crescendo ~2.000/dia
2. **FrequÃªncia:** AtualizaÃ§Ã£o a cada hora (24x/dia)
3. **Performance:** ExecuÃ§Ã£o em < 10 segundos (nÃ£o bloquear dashboards)
4. **Confiabilidade:** Retry automÃ¡tico, auditoria de execuÃ§Ãµes
5. **Dados MutÃ¡veis:** Conversas podem ser atualizadas (status, CSAT, resoluÃ§Ã£o)
6. **Economia:** Minimizar carga no banco remoto (read-only user)

### Problema
Como sincronizar eficientemente dados mutÃ¡veis de um banco remoto sem:
- Refazer carga completa (300k rows = 2-3 minutos)
- Perder atualizaÃ§Ãµes de conversas antigas
- Criar duplicatas
- Sobrecarregar banco remoto

---

## Alternativas Consideradas

### OpÃ§Ã£o 1: Full Load (Carga Completa)
```python
df = pd.read_sql("SELECT * FROM vw_conversations_analytics_final", conn)
df.to_sql("conversations_analytics", conn, if_exists='replace')
```
- **PrÃ³s:** Simples, garante consistÃªncia total
- **Contras:**
  - 300k rows = 2-3 minutos
  - Sobrecarga no banco remoto
  - Downtime do dashboard
  - Ineficiente para 24 execuÃ§Ãµes/dia
- **DecisÃ£o:** âŒ Rejeitado - inviÃ¡vel para produÃ§Ã£o

### OpÃ§Ã£o 2: Incremental Simples (Apenas Novos)
```python
last_id = get_max_id()
df = pd.read_sql(f"SELECT * FROM ... WHERE id > {last_id}", conn)
```
- **PrÃ³s:** RÃ¡pido para novos registros
- **Contras:**
  - **Perde atualizaÃ§Ãµes** de conversas antigas (status, CSAT)
  - NÃ£o detecta mudanÃ§as
- **DecisÃ£o:** âŒ Rejeitado - dados incompletos

### OpÃ§Ã£o 3: CDC (Change Data Capture) com Triggers
```sql
CREATE TRIGGER conversation_changes
AFTER UPDATE ON conversations
FOR EACH ROW EXECUTE FUNCTION notify_change();
```
- **PrÃ³s:** Captura mudanÃ§as em real-time
- **Contras:**
  - Requer permissÃµes de DBA no banco remoto
  - UsuÃ¡rio read-only nÃ£o pode criar triggers
  - Complexidade operacional
- **DecisÃ£o:** âŒ Rejeitado - permissÃµes insuficientes

### OpÃ§Ã£o 4: Incremental com Watermark (Timestamp-Based) âœ…
```python
watermark = get_last_watermark()  # 2025-11-10 10:00:00
df = pd.read_sql(f"""
    SELECT * FROM vw_conversations_analytics_final
    WHERE updated_at > '{watermark}'
    ORDER BY updated_at ASC
""", conn)
# UPSERT: INSERT novos, UPDATE existentes
```
- **PrÃ³s:**
  - Captura novos E atualizaÃ§Ãµes
  - Performance: apenas dados modificados
  - NÃ£o requer permissÃµes especiais
  - AuditÃ¡vel (watermark tracking)
- **Contras:**
  - Requer campo `updated_at` na fonte
  - LÃ³gica de UPSERT mais complexa
- **DecisÃ£o:** âœ… **ESCOLHIDO**

---

## DecisÃ£o

Implementar **ETL Pipeline V3 Incremental com Watermark Management:**

### Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ETL Pipeline V3 - Modular                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  1. Watermark Manager  â†â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚     - get_last_watermark()     â”‚  Auditoria                  â”‚
â”‚     - create_etl_execution()   â”‚                             â”‚
â”‚     - update_etl_execution()   â””â”€â”€â†’  etl_control (tabela)   â”‚
â”‚                                                               â”‚
â”‚  2. Extractor                                                â”‚
â”‚     - test_connection()                                      â”‚
â”‚     - extract_incremental(watermark_start)                   â”‚
â”‚     - extract_full()                                         â”‚
â”‚                                                               â”‚
â”‚  3. Transformer                                              â”‚
â”‚     - transform_data(df)                                     â”‚
â”‚     - validate_data(df)                                      â”‚
â”‚     - clean_columns()                                        â”‚
â”‚                                                               â”‚
â”‚  4. Loader                                                   â”‚
â”‚     - load_upsert(df) â† INSERT + UPDATE                     â”‚
â”‚     - load_full(df)                                          â”‚
â”‚     - batch_processing(1000 rows)                            â”‚
â”‚                                                               â”‚
â”‚  5. Logger                                                   â”‚
â”‚     - setup_logger()                                         â”‚
â”‚     - log_execution_summary()                                â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes-Chave

#### 1. Watermark Manager
```python
def get_last_watermark() -> Optional[datetime]:
    """ObtÃ©m timestamp da Ãºltima execuÃ§Ã£o bem-sucedida"""
    query = """
        SELECT watermark_end
        FROM etl_control
        WHERE status = 'success'
        ORDER BY execution_id DESC
        LIMIT 1
    """
    return result or None  # None = Full Load
```

#### 2. Extractor (Incremental)
```python
def extract_incremental(watermark_start: datetime) -> pd.DataFrame:
    """Extrai apenas dados novos/modificados"""
    query = f"""
        SELECT * FROM vw_conversations_analytics_final
        WHERE updated_at > '{watermark_start}'
        ORDER BY updated_at ASC
        LIMIT 10000  -- Safety limit
    """
    return pd.read_sql(query, source_conn)
```

#### 3. Loader (UPSERT)
```python
def load_upsert(df: pd.DataFrame) -> bool:
    """INSERT novos, UPDATE existentes"""
    query = """
        INSERT INTO conversations_analytics (
            conversation_id, tenant_id, status, ...
        ) VALUES %s
        ON CONFLICT (tenant_id, conversation_id)
        DO UPDATE SET
            status = EXCLUDED.status,
            updated_at = EXCLUDED.updated_at,
            etl_updated_at = NOW()
    """
    execute_batch(cursor, query, df.values, page_size=1000)
```

#### 4. Tabela de Auditoria
```sql
CREATE TABLE etl_control (
    execution_id SERIAL PRIMARY KEY,
    tenant_id INTEGER,
    load_type VARCHAR(50),  -- 'incremental' ou 'full'
    triggered_by VARCHAR(50),  -- 'manual', 'scheduler', 'api'
    status VARCHAR(50),  -- 'running', 'success', 'failed'
    rows_extracted INTEGER,
    rows_loaded INTEGER,
    watermark_start TIMESTAMP,
    watermark_end TIMESTAMP,
    started_at TIMESTAMP DEFAULT NOW(),
    ended_at TIMESTAMP,
    error_message TEXT
);
```

---

## Fluxo de ExecuÃ§Ã£o

### 1. Modo Incremental (PadrÃ£o)
```
â”œâ”€ START (disparado por cron)
â”œâ”€ Obter watermark: 2025-11-10 10:00:00
â”œâ”€ EXTRACT: SELECT WHERE updated_at > '10:00'
â”‚  â””â”€ Resultado: 1.542 rows (2-3 segundos)
â”œâ”€ TRANSFORM: Validar + Limpar (1 segundo)
â”œâ”€ LOAD: UPSERT em batches de 1000 (1-2 segundos)
â”œâ”€ UPDATE watermark: 2025-11-10 11:00:00
â””â”€ END (total: 4-6 segundos)
```

### 2. Modo Full Load (Primeira Vez / --full)
```
â”œâ”€ START
â”œâ”€ Watermark: None (full load)
â”œâ”€ EXTRACT: SELECT * (sem filtro)
â”‚  â””â”€ Resultado: 300.000 rows (60-90 segundos)
â”œâ”€ TRANSFORM: Validar + Limpar (15-20 segundos)
â”œâ”€ LOAD: UPSERT em batches (30-40 segundos)
â”œâ”€ SET watermark: 2025-11-10 11:00:00
â””â”€ END (total: 2-3 minutos)
```

---

## ConsequÃªncias

### Positivas âœ…

1. **Performance:** 2-5 segundos (incremental) vs 2-3 minutos (full)
2. **Economia:** 99% menos dados transferidos do banco remoto
3. **AtualizaÃ§Ã£o:** Captura mudanÃ§as em conversas antigas (CSAT, status)
4. **Auditoria:** HistÃ³rico completo de execuÃ§Ãµes em `etl_control`
5. **Confiabilidade:** Retry automÃ¡tico, rollback em caso de erro
6. **Escalabilidade:** Performance constante independente do volume total
7. **Flexibilidade:** Suporta tanto incremental quanto full load

### Negativas âŒ

1. **Complexidade:** Mais cÃ³digo que full load simples
2. **DependÃªncia:** Requer campo `updated_at` confiÃ¡vel na fonte
3. **Testes:** Precisa testar cenÃ¡rios de atualizaÃ§Ã£o, nÃ£o sÃ³ inserÃ§Ã£o
4. **Monitoramento:** Requer alertas para falhas de watermark

### Riscos e MitigaÃ§Ãµes

| Risco | Probabilidade | Impacto | MitigaÃ§Ã£o |
|-------|--------------|---------|-----------|
| updated_at nÃ£o atualizado | Baixa | Alto | ValidaÃ§Ã£o na view remota |
| Watermark corrompido | Baixa | MÃ©dio | Backup em arquivo + tabela |
| Dados duplicados | Baixa | MÃ©dio | UNIQUE constraint (tenant_id, conversation_id) |
| ExecuÃ§Ã£o concorrente | Baixa | Alto | Lock na tabela etl_control |
| Batch muito grande | MÃ©dia | MÃ©dio | LIMIT 10.000 no extractor |

---

## MÃ©tricas de Sucesso

### Performance
- âœ… Incremental: < 10 segundos (99% das execuÃ§Ãµes)
- âœ… Full load: < 5 minutos (primeira vez)
- âœ… Taxa de sucesso: > 99.5%

### Dados
- âœ… 0 duplicatas (validado por UNIQUE constraint)
- âœ… 0 dados perdidos (auditoria de contagem)
- âœ… LatÃªncia: < 1 hora (dados no dashboard)

### Operacional
- âœ… 24 execuÃ§Ãµes/dia (agendamento via cron)
- âœ… Logs estruturados em `logs/etl/`
- âœ… Alertas automÃ¡ticos em caso de falha

---

## ImplementaÃ§Ã£o

### Fase 1: ModularizaÃ§Ã£o (Completo)
- âœ… `etl/extractor.py` (250 linhas)
- âœ… `etl/transformer.py` (180 linhas)
- âœ… `etl/loader.py` (220 linhas)
- âœ… `etl/watermark_manager.py` (150 linhas)
- âœ… `etl/logger.py` (100 linhas)

### Fase 2: Pipeline V3 (Completo)
- âœ… `etl_pipeline_v3.py` (orquestrador)
- âœ… Suporte a flags: `--full`, `--triggered-by`
- âœ… Auditoria em `etl_control`

### Fase 3: Agendamento (Completo)
- âœ… Cron job: a cada hora
- âœ… Systemd timer (alternativa)
- âœ… Scripts de monitoramento

### Fase 4: Multi-Tenant (Em Progresso)
- ğŸš§ ETL V4: suporte a mÃºltiplos tenants
- ğŸš§ Watermark por tenant
- ğŸš§ ParalelizaÃ§Ã£o de execuÃ§Ãµes

---

## Monitoramento

### Queries de Monitoramento
```sql
-- Ãšltimas 5 execuÃ§Ãµes
SELECT
    execution_id,
    load_type,
    status,
    rows_extracted,
    rows_loaded,
    EXTRACT(EPOCH FROM (ended_at - started_at)) as duration_seconds,
    started_at
FROM etl_control
ORDER BY execution_id DESC
LIMIT 5;

-- Taxa de sucesso (Ãºltimas 24h)
SELECT
    COUNT(*) as total,
    COUNT(*) FILTER (WHERE status = 'success') as success,
    COUNT(*) FILTER (WHERE status = 'failed') as failed,
    ROUND(100.0 * COUNT(*) FILTER (WHERE status = 'success') / COUNT(), 2) as success_rate
FROM etl_control
WHERE started_at > NOW() - INTERVAL '24 hours';
```

### Alertas
```bash
# Script de alerta (scripts/etl/monitor.sh)
if [ $(psql -t -c "SELECT COUNT(*) FROM etl_control WHERE status='failed' AND started_at > NOW() - INTERVAL '1 hour'") -gt 0 ]; then
    echo "ALERTA: ETL falhou na Ãºltima hora!"
    # Enviar notificaÃ§Ã£o (email, Slack, etc.)
fi
```

---

## ReferÃªncias

- [PostgreSQL UPSERT (ON CONFLICT)](https://www.postgresql.org/docs/15/sql-insert.html#SQL-ON-CONFLICT)
- [Pandas read_sql Chunking](https://pandas.pydata.org/docs/reference/api/pandas.read_sql.html)
- [Watermark Pattern (Kafka)](https://kafka.apache.org/documentation/#streams_concepts_time)
- DocumentaÃ§Ã£o interna: `docs/ETL_V3_README.md`

---

## Notas de RevisÃ£o

**PrÃ³xima RevisÃ£o:** 2025-12-01
**ResponsÃ¡vel:** Isaac (GenIAI)
**Gatilhos de RevisÃ£o:**
- Performance degradada (> 30 segundos)
- Taxa de falha > 1%
- ImplementaÃ§Ã£o de CDC no banco remoto
- MigraÃ§Ã£o para streaming (Kafka, Debezium)