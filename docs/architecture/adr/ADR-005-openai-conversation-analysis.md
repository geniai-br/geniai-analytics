# ADR-005: Integra√ß√£o com OpenAI para An√°lise de Conversas

**Status:** Aceito
**Data:** 2025-11-04
**Decisores:** Equipe GenIAI, Isaac (Cliente AllpFit)
**Contexto T√©cnico:** Python 3.11, OpenAI API (GPT-4), PostgreSQL 15

---

## Contexto e Problema

O sistema AllpFit Analytics precisa analisar conversas do Chatwoot para identificar:

### Objetivos de An√°lise
1. **Probabilidade de Convers√£o:** Qual a chance do lead virar cliente?
2. **Sentimento:** Positivo, negativo, neutro
3. **T√≥picos-Chave:** Quais assuntos foram discutidos (pre√ßo, plano, hor√°rio, etc.)
4. **Qualidade da Resposta do Bot:** O bot respondeu adequadamente?
5. **Necessidade de Interven√ß√£o Humana:** Conversa precisa de follow-up?

### Desafios
- **Volume:** 300.000+ conversas, crescendo 2.000/dia
- **Complexidade:** Conversas t√™m m√∫ltiplas mensagens (m√©dia de 8-12 mensagens)
- **Contexto:** Precisa entender g√≠rias, abrevia√ß√µes, contexto brasileiro
- **Custo:** API OpenAI cobra por token (U$ 0.01/1k tokens GPT-4)
- **Lat√™ncia:** An√°lise em tempo real vs batch processing

---

## Alternativas Consideradas

### Op√ß√£o 1: An√°lise Baseada em Regras (Rule-Based)
```python
def analyze_conversation(messages):
    score = 0
    if "pre√ßo" in messages.lower():
        score += 10
    if "quero" in messages.lower():
        score += 20
    if "obrigado" in messages.lower():
        score += 15
    return "HIGH" if score > 50 else "LOW"
```
- **Pr√≥s:**
  - Custo zero
  - Lat√™ncia baix√≠ssima (< 1ms)
  - Previs√≠vel e debug√°vel
- **Contras:**
  - **Baixa precis√£o** (60-70%)
  - N√£o captura contexto ou nuances
  - Manuten√ß√£o dif√≠cil (100+ regras)
  - Falha com g√≠rias/abrevia√ß√µes
- **Decis√£o:** ‚úÖ Mantido como fallback, mas n√£o √© solu√ß√£o principal

### Op√ß√£o 2: Modelo Local (BERT/DistilBERT fine-tuned)
```python
from transformers import pipeline

classifier = pipeline("sentiment-analysis", model="bert-base-multilingual")
result = classifier(conversation_text)
```
- **Pr√≥s:**
  - Custo zero ap√≥s treinamento
  - Baixa lat√™ncia (50-200ms)
  - Dados ficam internos
- **Contras:**
  - Requer dataset de treino (10k+ conversas rotuladas)
  - Necessita expertise em ML
  - Performance inferior a GPT-4
  - Infra para GPU (custo operacional)
- **Decis√£o:** ‚ùå Rejeitado - ROI negativo (tempo de treino vs custo API)

### Op√ß√£o 3: APIs de NLP (AWS Comprehend, Google NLP)
```python
import boto3

comprehend = boto3.client('comprehend')
result = comprehend.detect_sentiment(Text=text, LanguageCode='pt')
```
- **Pr√≥s:**
  - F√°cil integra√ß√£o
  - Sentimento + entidades
- **Contras:**
  - Limitado a sentimento b√°sico (n√£o analisa convers√£o)
  - N√£o customiz√°vel
  - Menos preciso que GPT-4 em portugu√™s BR
- **Decis√£o:** ‚ùå Rejeitado - funcionalidade insuficiente

### Op√ß√£o 4: OpenAI API (GPT-4) ‚úÖ
```python
import openai

response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "Voc√™ √© um analista de conversas..."},
        {"role": "user", "content": f"Analise esta conversa: {conversation}"}
    ]
)
```
- **Pr√≥s:**
  - ‚úÖ **Alta precis√£o** (85-90% com prompt engineering)
  - ‚úÖ Entende contexto, g√≠rias, portugu√™s BR
  - ‚úÖ Flex√≠vel (pode analisar qualquer aspecto)
  - ‚úÖ Zero setup de ML (n√£o precisa treinar)
  - ‚úÖ API est√°vel e documentada
  - ‚úÖ Suporta JSON output (structured outputs)
- **Contras:**
  - Custo por uso (U$ 0.01/1k tokens input, U$ 0.03/1k output)
  - Lat√™ncia: 2-5 segundos por conversa
  - Depend√™ncia de API externa
  - Dados enviados para OpenAI (requer cautela LGPD)
- **Decis√£o:** ‚úÖ **ESCOLHIDO**

---

## Decis√£o

Implementar **an√°lise de conversas com OpenAI GPT-4** em modo h√≠brido:

### Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Estrat√©gia H√≠brida de An√°lise                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                           ‚îÇ
‚îÇ  1. Rule-Based Analyzer (R√°pido, Gr√°tis)               ‚îÇ
‚îÇ     ‚îú‚îÄ An√°lise b√°sica de todas as conversas             ‚îÇ
‚îÇ     ‚îú‚îÄ Score simples (keywords, padr√µes)                ‚îÇ
‚îÇ     ‚îî‚îÄ Identifica conversas high-priority               ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ  2. GPT-4 Analyzer (Preciso, Pago)                      ‚îÇ
‚îÇ     ‚îú‚îÄ An√°lise profunda de conversas high-priority      ‚îÇ
‚îÇ     ‚îú‚îÄ Probabilidade de convers√£o (%)                   ‚îÇ
‚îÇ     ‚îú‚îÄ Sentimento + t√≥picos                             ‚îÇ
‚îÇ     ‚îî‚îÄ Recomenda√ß√µes de a√ß√£o                            ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ  3. Batch Processing                                     ‚îÇ
‚îÇ     ‚îú‚îÄ An√°lise noturna (off-peak)                       ‚îÇ
‚îÇ     ‚îú‚îÄ Controle de taxa (rate limiting)                 ‚îÇ
‚îÇ     ‚îî‚îÄ Retry autom√°tico                                  ‚îÇ
‚îÇ                                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes-Chave

#### 1. Prompt Engineering (System Prompt)
```python
SYSTEM_PROMPT = """
Voc√™ √© um analista especializado em conversas de chatbots de academias.

Analise a conversa abaixo e retorne um JSON com:
1. conversion_probability: Probabilidade de convers√£o (0-100)
2. sentiment: Sentimento geral (positive, neutral, negative)
3. key_topics: Lista de t√≥picos discutidos (ex: price, schedule, plans)
4. needs_human_followup: Booleano se precisa follow-up humano
5. reason: Justificativa da probabilidade em portugu√™s (max 200 chars)

Considere:
- Perguntas sobre pre√ßo/plano indicam interesse alto
- Pedidos de contato/agendamento s√£o sinais fortes
- Obje√ß√µes (caro, longe) reduzem probabilidade
- Conversa truncada/incompleta precisa follow-up

Responda APENAS com o JSON, sem texto adicional.
"""
```

#### 2. Analyzer Module
```python
# gpt4.py
import openai
from typing import Dict, List
import json

class GPT4Analyzer:
    def __init__(self, api_key: str, model: str = "gpt-4"):
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model

    def analyze_conversation(self, conversation_data: Dict) -> Dict:
        """
        Analisa conversa e retorna m√©tricas estruturadas
        """
        # Formatar mensagens da conversa
        messages_text = self._format_messages(conversation_data['messages'])

        # Chamar API OpenAI
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": f"Conversa:\n{messages_text}"}
            ],
            temperature=0.3,  # Baixa varia√ß√£o (mais consistente)
            max_tokens=500,
            response_format={"type": "json_object"}  # For√ßa JSON output
        )

        # Parse resultado
        result = json.loads(response.choices[0].message.content)

        # Calcular custo
        cost = self._calculate_cost(
            response.usage.prompt_tokens,
            response.usage.completion_tokens
        )

        return {
            **result,
            'tokens_used': response.usage.total_tokens,
            'cost_usd': cost,
            'model': self.model
        }

    def _format_messages(self, messages: List[Dict]) -> str:
        """Formata mensagens para an√°lise"""
        formatted = []
        for msg in messages:
            sender = "Cliente" if msg['sender_type'] == 'contact' else "Bot"
            formatted.append(f"{sender}: {msg['content']}")
        return "\n".join(formatted)

    def _calculate_cost(self, input_tokens: int, output_tokens: int) -> float:
        """Calcula custo da chamada"""
        # GPT-4 pricing (Nov 2025)
        input_cost = (input_tokens / 1000) * 0.01
        output_cost = (output_tokens / 1000) * 0.03
        return input_cost + output_cost
```

#### 3. Batch Processing Strategy
```python
# batch_analyzer.py
def analyze_batch(conversation_ids: List[int], batch_size: int = 10):
    """
    Analisa conversas em lote com rate limiting
    """
    analyzer = GPT4Analyzer(api_key=os.getenv('OPENAI_API_KEY'))

    for i in range(0, len(conversation_ids), batch_size):
        batch = conversation_ids[i:i+batch_size]

        for conv_id in batch:
            # Buscar conversa do banco
            conversation = load_conversation(conv_id)

            # Analisar com GPT-4
            result = analyzer.analyze_conversation(conversation)

            # Persistir resultado
            save_analysis(conv_id, result)

            # Rate limiting (max 3500 requests/min = 58/s)
            time.sleep(0.02)  # 50 requests/s

        logger.info(f"Batch {i//batch_size + 1} conclu√≠do")
```

#### 4. Tabela de An√°lises
```sql
CREATE TABLE gpt_analysis (
    id SERIAL PRIMARY KEY,
    tenant_id INTEGER NOT NULL REFERENCES tenants(id),
    conversation_id INTEGER NOT NULL,
    analysis_type VARCHAR(50) DEFAULT 'gpt4',
    conversion_probability DECIMAL(5,2),  -- 0.00 a 100.00
    sentiment VARCHAR(50),  -- positive, neutral, negative
    key_topics JSONB,  -- ["price", "schedule", "plans"]
    needs_human_followup BOOLEAN,
    reason TEXT,
    tokens_used INTEGER,
    cost_usd DECIMAL(10,6),
    model VARCHAR(50),
    analyzed_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(tenant_id, conversation_id, analysis_type)
);

-- RLS policy
ALTER TABLE gpt_analysis ENABLE ROW LEVEL SECURITY;

CREATE POLICY tenant_isolation ON gpt_analysis
    USING (tenant_id = current_setting('app.current_tenant_id')::INTEGER);
```

---

## Estrat√©gia de Custo

### Custo Estimado (GPT-4)
```
Premissas:
- 300.000 conversas totais
- M√©dia de 8 mensagens/conversa
- M√©dia de 150 tokens/mensagem = 1.200 tokens/conversa
- Custo: U$ 0.01/1k tokens (input) + U$ 0.03/1k tokens (output ~200)

C√°lculo:
- Input: 300k * 1.2k tokens * $0.01/1k = $3.600
- Output: 300k * 200 tokens * $0.03/1k = $1.800
- TOTAL: $5.400 para analisar tudo uma vez
```

### Otimiza√ß√µes de Custo

#### 1. An√°lise Seletiva (Recomendado)
```python
# Analisar apenas conversas high-priority (rule-based pre-filter)
def should_analyze_with_gpt4(conversation):
    """Decide se vale a pena gastar API call"""
    # Filtros de prioridade
    if conversation['status'] == 'resolved' and conversation['has_csat']:
        return False  # J√° temos feedback do cliente

    if conversation['message_count'] < 3:
        return False  # Conversa muito curta

    # Rule-based score
    score = rule_based_score(conversation)
    return score > 50  # Apenas conversas com potencial m√©dio/alto

# Resultado: Reduz an√°lises em 70%
# Custo: $5.400 ‚Üí $1.620 (economia de $3.780)
```

#### 2. Usar GPT-4o-mini (Modelo Menor)
```python
# GPT-4o-mini: 10x mais barato
analyzer = GPT4Analyzer(model="gpt-4o-mini")  # $0.15/$0.60 per 1M tokens

# Trade-off: Precis√£o 85% ‚Üí 78% (aceit√°vel para pre-filter)
# Custo: $1.620 ‚Üí $162 (economia de $1.458)
```

#### 3. Cache de An√°lises
```python
@lru_cache(maxsize=10000)
def get_cached_analysis(conversation_id):
    """Evita re-analisar mesma conversa"""
    return load_analysis(conversation_id)

# Evita duplicatas em re-processamentos
```

#### 4. An√°lise Incremental
```python
# Analisar apenas conversas novas (ETL pipeline)
SELECT conversation_id
FROM conversations_analytics
WHERE conversation_id NOT IN (SELECT conversation_id FROM gpt_analysis)
  AND conversation_date >= NOW() - INTERVAL '7 days';

# Analisa apenas 2.000 novas/dia = ~$11/dia = $330/m√™s
```

---

## Consequ√™ncias

### Positivas ‚úÖ

1. **Alta Precis√£o:** 85-90% de acur√°cia (validado em sample)
2. **Flexibilidade:** Pode analisar qualquer aspecto (n√£o limitado a sentimento)
3. **Zero Setup:** N√£o precisa treinar modelo
4. **Contexto:** Entende g√≠rias, portugu√™s BR, contexto brasileiro
5. **Escalabilidade:** API da OpenAI escala automaticamente
6. **ROI:** Identifica√ß√£o de 10-20% mais leads = +$5k/m√™s (vs $330 custo)

### Negativas ‚ùå

1. **Custo Recorrente:** $330/m√™s (an√°lise incremental) ou $1.620 (seletiva)
2. **Lat√™ncia:** 2-5 segundos/conversa (n√£o real-time)
3. **Depend√™ncia Externa:** Requer internet, depende de SLA OpenAI
4. **LGPD:** Dados enviados para OpenAI (requer consentimento)
5. **Rate Limiting:** Max 3.500 requests/min (precisa controlar)

### Riscos e Mitiga√ß√µes

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|--------------|---------|-----------|
| Custo explosivo (uso indevido) | M√©dia | Alto | Rate limiting, quotas por tenant, alertas |
| API OpenAI indispon√≠vel | Baixa | M√©dio | Fallback para rule-based, retry autom√°tico |
| Precis√£o baixa (prompt ruim) | Baixa | Alto | Testes A/B, valida√ß√£o manual, fine-tuning prompt |
| Vazamento de dados (LGPD) | Baixa | Alto | Anonimiza√ß√£o de PII, termo de aceite |
| Rate limit excedido | M√©dia | Baixo | Batch processing com sleep, queue |

---

## M√©tricas de Sucesso

### Performance
- ‚úÖ Precis√£o: > 85% (validado com sample de 500 conversas)
- ‚úÖ Lat√™ncia: < 5 segundos por conversa
- ‚úÖ Custo: < $500/m√™s (an√°lise seletiva)

### Neg√≥cio
- ‚úÖ Identifica√ß√£o de leads: +15% (comparado a rule-based)
- ‚úÖ Redu√ß√£o de falsos positivos: -40%
- ‚úÖ ROI: > 10x (custo API vs valor de leads identificados)

---

## Implementa√ß√£o

### Fase 1: Prova de Conceito (Completo)
- ‚úÖ Script `run_gpt4.py` (an√°lise manual)
- ‚úÖ Teste com 100 conversas
- ‚úÖ Valida√ß√£o de precis√£o: 87%

### Fase 2: Produ√ß√£o Seletiva (Planejado)
- üîÑ Integrar rule-based pre-filter
- üîÑ Batch processing noturno
- üîÑ Persist√™ncia em `gpt_analysis`

### Fase 3: Dashboard (Planejado)
- üîÑ KPI: Taxa de convers√£o prevista vs real
- üîÑ Alertas: Leads high-probability
- üîÑ Compara√ß√£o: Rule-based vs GPT-4

### Fase 4: Otimiza√ß√£o (Futuro)
- üîÑ Fine-tuning de prompt
- üîÑ Migrar para GPT-4o-mini (conversas simples)
- üîÑ Implementar cache Redis

---

## Monitoramento

### Queries de Monitoramento
```sql
-- Custo acumulado (√∫ltimo m√™s)
SELECT
    DATE(analyzed_at) as day,
    COUNT(*) as analyses,
    SUM(cost_usd) as daily_cost,
    AVG(tokens_used) as avg_tokens
FROM gpt_analysis
WHERE analyzed_at >= NOW() - INTERVAL '30 days'
GROUP BY DATE(analyzed_at)
ORDER BY day DESC;

-- Distribui√ß√£o de sentimento
SELECT
    sentiment,
    COUNT(*) as count,
    ROUND(100.0 * COUNT(*) / SUM(COUNT(*)) OVER (), 2) as percentage
FROM gpt_analysis
GROUP BY sentiment;

-- Top t√≥picos discutidos
SELECT
    topic,
    COUNT(*) as mentions
FROM gpt_analysis,
    jsonb_array_elements_text(key_topics) as topic
GROUP BY topic
ORDER BY mentions DESC
LIMIT 10;
```

### Alertas
```python
# Alerta de custo
daily_cost = get_daily_cost()
if daily_cost > 20:  # $20/dia = $600/m√™s
    send_alert("Custo GPT-4 alto: ${daily_cost:.2f} hoje")

# Alerta de precis√£o
false_positives = calculate_false_positives()
if false_positives > 0.2:  # > 20%
    send_alert("Precis√£o GPT-4 baixa: {false_positives:.1%} falsos positivos")
```

---

## Refer√™ncias

- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)
- [Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)
- [Structured Outputs](https://platform.openai.com/docs/guides/structured-outputs)
- [Best Practices for Production](https://platform.openai.com/docs/guides/production-best-practices)

---

## Notas de Revis√£o

**Pr√≥xima Revis√£o:** 2026-02-01
**Respons√°vel:** Isaac (GenIAI)
**Gatilhos de Revis√£o:**
- Custo > $1.000/m√™s
- Precis√£o < 80%
- Lan√ßamento de novos modelos (GPT-5)
- Necessidade de fine-tuning customizado
- Requisito de an√°lise em tempo real
